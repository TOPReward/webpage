<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="TOPReward: Token Probabilities as Hidden Zero-Shot Rewards for Robotics - A zero-shot progress estimation framework using VLM token likelihoods for robotic manipulation.">
  <meta name="keywords" content="TOPReward, Token Probabilities, Zero-Shot Rewards, Robot Manipulation, Reinforcement Learning, Vision-Language Models, ManiRewardBench, VLM, Robotics">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TOPReward: Token Probabilities as Hidden Zero-Shot Rewards for Robotics</title>

  <!-- Favicon -->
  <link rel="icon" type="image/png" href="./static/images/favicon.ico" sizes="any">
 

  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <style>
    :root {
      --primary: #2563eb;
      --primary-dark: #1d4ed8;
      --secondary: #7c3aed;
      --accent: #06b6d4;
      --success: #10b981;
      --warning: #f59e0b;
      --bg-light: #f8fafc;
      --bg-dark: #0f172a;
      --text-primary: #1e293b;
      --text-secondary: #64748b;
      --border: #e2e8f0;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
      line-height: 1.7;
      color: var(--text-primary);
      background: #fff;
    }

    .container {
      max-width: 850px;
      margin: 0 auto;
      padding: 0 24px;
    }

    /* Hero Section */
    .hero {
      background: linear-gradient(135deg, #1e3a5f 0%, #0f172a 50%, #1a1a2e 100%);
      color: white;
      padding: 80px 0 60px;
      position: relative;
      overflow: hidden;
    }

    .hero::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: url("data:image/svg+xml,%3Csvg width='60' height='60' viewBox='0 0 60 60' xmlns='http://www.w3.org/2000/svg'%3E%3Cg fill='none' fill-rule='evenodd'%3E%3Cg fill='%239C92AC' fill-opacity='0.05'%3E%3Cpath d='M36 34v-4h-2v4h-4v2h4v4h2v-4h4v-2h-4zm0-30V0h-2v4h-4v2h4v4h2V6h4V4h-4zM6 34v-4H4v4H0v2h4v4h2v-4h4v-2H6zM6 4V0H4v4H0v2h4v4h2V6h4V4H6z'/%3E%3C/g%3E%3C/g%3E%3C/svg%3E");
    }

    .hero-content {
      position: relative;
      z-index: 1;
      text-align: center;
    }

    .venue-badge {
      display: inline-block;
      background: rgba(255,255,255,0.1);
      border: 1px solid rgba(255,255,255,0.2);
      padding: 6px 16px;
      border-radius: 20px;
      font-size: 0.85rem;
      font-weight: 500;
      margin-bottom: 24px;
      backdrop-filter: blur(10px);
    }

    .hero h1 {
      font-size: 2.75rem;
      font-weight: 700;
      line-height: 1.2;
      margin-bottom: 20px;
      letter-spacing: -0.02em;
    }

    .hero h1 .highlight {
      background: linear-gradient(90deg, var(--accent), var(--primary));
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
    }

    .authors {
      font-size: 1.1rem;
      color: rgba(255,255,255,0.8);
      margin-bottom: 32px;
    }

    .btn-group {
      display: flex;
      gap: 12px;
      justify-content: center;
      flex-wrap: wrap;
    }

    .btn {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 12px 24px;
      border-radius: 8px;
      font-weight: 500;
      font-size: 0.95rem;
      text-decoration: none;
      transition: all 0.2s;
    }

    .btn-primary {
      background: white;
      color: var(--bg-dark);
    }

    .btn-primary:hover {
      background: #f1f5f9;
      transform: translateY(-2px);
    }

    .btn-outline {
      background: white;
      color: var(--bg-dark);
      border: 1px solid rgba(255,255,255,0.3);
    }

    .btn-outline:hover {
      background: #f1f5f9;
      border-color: rgba(255,255,255,0.5);
    }

    /* Teaser */
    .teaser {
      padding: 60px 0 40px;
      background: var(--bg-light);
    }

    .teaser-img {
      width: 100%;
      border-radius: 12px;
      box-shadow: 0 20px 60px rgba(0,0,0,0.1);
    }

    .teaser-caption {
      max-width: 900px;
      margin: 24px auto 0;
      text-align: center;
      color: var(--text-secondary);
      font-size: 1rem;
      line-height: 1.8;
    }

    .teaser-caption b {
      color: var(--text-primary);
    }

    /* Section Styles */
    section {
      padding: 70px 0;
    }

    section.alt-bg {
      background: var(--bg-light);
    }

    .section-title {
      font-size: 2rem;
      font-weight: 700;
      margin-bottom: 24px;
      color: var(--text-primary);
      display: flex;
      align-items: center;
      gap: 12px;
    }

    .section-title .icon {
      width: 40px;
      height: 40px;
      background: linear-gradient(135deg, var(--primary), var(--secondary));
      border-radius: 10px;
      display: flex;
      align-items: center;
      justify-content: center;
      color: white;
      font-size: 1.1rem;
    }

    .prose {
      font-size: 1.05rem;
      color: var(--text-secondary);
      line-height: 1.8;
    }

    .prose p {
      margin-bottom: 16px;
    }

    .prose strong {
      color: var(--text-primary);
      font-weight: 600;
    }

    /* Key Stats */
    .stats-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 20px;
      margin: 40px 0;
    }

    .stat-card {
      background: white;
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 24px;
      text-align: center;
      transition: all 0.2s;
    }

    .stat-card:hover {
      border-color: var(--primary);
      box-shadow: 0 4px 20px rgba(37, 99, 235, 0.1);
    }

    .stat-value {
      font-size: 2.5rem;
      font-weight: 700;
      color: var(--primary);
      line-height: 1;
    }

    .stat-label {
      font-size: 0.9rem;
      color: var(--text-secondary);
      margin-top: 8px;
    }

    /* Method Components */
    .method-figure {
      margin: 30px 0;
    }

    .method-figure img {
      width: 100%;
      border-radius: 12px;
      border: 1px solid var(--border);
    }

    .method-figure figcaption {
      margin-top: 16px;
      font-size: 0.95rem;
      color: var(--text-secondary);
      text-align: center;
    }

    .components-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 24px;
      margin-top: 40px;
    }

    .component-card {
      background: white;
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 28px;
      transition: all 0.2s;
    }

    .component-card:hover {
      border-color: var(--primary);
      transform: translateY(-4px);
      box-shadow: 0 12px 40px rgba(0,0,0,0.08);
    }

    .component-num {
      width: 32px;
      height: 32px;
      background: linear-gradient(135deg, var(--primary), var(--secondary));
      color: white;
      border-radius: 8px;
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 600;
      font-size: 0.9rem;
      margin-bottom: 16px;
    }

    .component-card h4 {
      font-size: 1.1rem;
      font-weight: 600;
      margin-bottom: 12px;
      color: var(--text-primary);
    }

    .component-card p {
      font-size: 0.95rem;
      color: var(--text-secondary);
      line-height: 1.7;
    }

    /* Results Tables */
    .results-table-container {
      overflow-x: auto;
      margin: 30px 0;
    }

    .results-table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.9rem;
    }

    .results-table th,
    .results-table td {
      padding: 14px 16px;
      text-align: center;
      border-bottom: 1px solid var(--border);
    }

    .results-table th {
      background: var(--bg-light);
      font-weight: 600;
      color: var(--text-primary);
    }

    .results-table tr:hover {
      background: #f8fafc;
    }

    .results-table .highlight-row {
      background: linear-gradient(90deg, rgba(16, 185, 129, 0.08), rgba(6, 182, 212, 0.08));
      font-weight: 600;
    }

    .results-table .highlight-row td {
      color: var(--text-primary);
    }

    .results-table .method-name {
      text-align: left;
      font-weight: 500;
    }

    /* Figure Grid */
    .figure-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
      gap: 30px;
      margin: 30px 0;
    }

    .figure-item {
      background: white;
      border: 1px solid var(--border);
      border-radius: 12px;
      overflow: hidden;
    }

    .figure-item img {
      width: 100%;
      display: block;
    }

    .figure-item figcaption {
      padding: 16px 20px;
      font-size: 0.9rem;
      color: var(--text-secondary);
      background: var(--bg-light);
    }

    .figure-item figcaption strong {
      color: var(--text-primary);
    }

    .full-figure {
      margin: 30px 0;
    }

    .full-figure img {
      width: 100%;
      border-radius: 12px;
      border: 1px solid var(--border);
    }

    .full-figure figcaption {
      margin-top: 16px;
      font-size: 0.95rem;
      color: var(--text-secondary);
      line-height: 1.7;
    }

    /* Video Sections */
    .video-section-title {
      font-size: 1.25rem;
      font-weight: 600;
      margin: 40px 0 20px;
      padding-bottom: 12px;
      border-bottom: 2px solid var(--primary);
      display: inline-block;
    }

    .video-grid {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 20px;
    }

    .comparison-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 24px;
      margin-top: 30px;
    }

    .video-card {
      background: white;
      border: 1px solid var(--border);
      border-radius: 12px;
      overflow: hidden;
      transition: all 0.2s;
    }

    .video-card:hover {
      border-color: var(--primary);
      box-shadow: 0 8px 30px rgba(0,0,0,0.08);
    }

    .video-card video {
      width: 100%;
      display: block;
    }

    .video-card .video-label {
      padding: 12px 16px;
      font-size: 0.9rem;
      font-weight: 500;
      color: var(--text-primary);
      background: var(--bg-light);
      text-align: center;
    }

    .video-placeholder {
      aspect-ratio: 16/10;
      background: linear-gradient(135deg, #f1f5f9, #e2e8f0);
      display: flex;
      align-items: center;
      justify-content: center;
      color: var(--text-secondary);
      font-size: 0.9rem;
      font-style: italic;
    }

    /* Key Findings */
    .findings-list {
      list-style: none;
      margin: 24px 0;
    }

    .findings-list li {
      padding: 16px 20px;
      background: white;
      border: 1px solid var(--border);
      border-radius: 10px;
      margin-bottom: 12px;
      display: flex;
      gap: 14px;
      align-items: flex-start;
    }

    .findings-list li::before {
      content: '✓';
      width: 24px;
      height: 24px;
      background: var(--success);
      color: white;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.75rem;
      flex-shrink: 0;
      margin-top: 2px;
    }

    .findings-list strong {
      color: var(--text-primary);
    }

    /* BibTeX */
    .bibtex-box {
      background: var(--bg-dark);
      border-radius: 12px;
      padding: 24px;
      overflow-x: auto;
    }

    .bibtex-box pre {
      color: #e2e8f0;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.85rem;
      line-height: 1.6;
      margin: 0;
    }

    /* Footer */
    footer {
      background: var(--bg-dark);
      color: rgba(255,255,255,0.7);
      padding: 40px 0;
      text-align: center;
      font-size: 0.9rem;
    }

    footer a {
      color: var(--accent);
      text-decoration: none;
    }

    .check { color: green; font-weight: bold; }
    .cross { color: red; font-weight: bold; }

    .demo-card {
      background: white;
      border: 1px solid var(--border);
      border-radius: 16px;
      overflow: hidden;
      margin-bottom: 20px;
    }
    .demo-video-header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 14px 20px;
      border-bottom: 1px solid var(--border);
      background: var(--bg-light);
      flex-wrap: wrap;
      gap: 8px;
    }
    .demo-task-label { font-size: 0.9rem; color: var(--text-secondary); }
    .demo-task-label strong { color: var(--text-primary); }
    .demo-t-badge {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.8rem;
      background: var(--primary);
      color: white;
      padding: 3px 12px;
      border-radius: 20px;
      white-space: nowrap;
    }
    .demo-video-wrap {
      position: relative;
      width: 50%;
      margin: 0 auto;
      background: #000;
      aspect-ratio: 16/10;
      overflow: hidden;
    }
    .demo-video-wrap video { width: 100%; height: 100%; object-fit: cover; display: block; }
    .demo-vid-cursor {
      position: absolute;
      top: 0; bottom: 0;
      width: 2px;
      background: rgba(37,99,235,0.9);
      box-shadow: 0 0 10px rgba(37,99,235,0.5);
      pointer-events: none;
      left: 0;
      transition: left 0.04s linear;
    }
    .demo-scrubber-wrap { padding: 14px 20px 8px; }
    .demo-scrubber-labels {
      display: flex;
      justify-content: space-between;
      font-size: 0.78rem;
      color: var(--text-secondary);
      font-family: 'JetBrains Mono', monospace;
      margin-bottom: 6px;
    }
    .demo-scrubber {
      -webkit-appearance: none; appearance: none;
      width: 100%; height: 5px; border-radius: 3px;
      background: var(--border); outline: none; cursor: pointer;
    }
    .demo-scrubber::-webkit-slider-thumb {
      -webkit-appearance: none;
      width: 18px; height: 18px; border-radius: 50%;
      background: var(--primary);
      box-shadow: 0 0 0 3px rgba(37,99,235,0.2);
      cursor: grab; transition: transform 0.1s;
    }
    .demo-scrubber:active::-webkit-slider-thumb { transform: scale(1.2); cursor: grabbing; }
    .demo-scrubber::-moz-range-thumb { width: 18px; height: 18px; border-radius: 50%; background: var(--primary); border: none; cursor: grab; }
    .demo-controls {
      display: flex; align-items: center; justify-content: center;
      gap: 10px; padding: 12px 20px 18px; flex-wrap: wrap;
    }
    .demo-btn {
      padding: 7px 18px; border-radius: 8px;
      border: 1px solid var(--border); background: var(--bg-light);
      color: var(--text-primary);
      font-family: 'Inter', sans-serif; font-size: 0.85rem; font-weight: 500;
      cursor: pointer; transition: all 0.15s;
    }
    .demo-btn:hover { border-color: var(--primary); color: var(--primary); }
    .demo-btn-play { background: var(--primary); color: white; border-color: var(--primary); min-width: 90px; }
    .demo-btn-play:hover { background: var(--primary-dark); color: white; }
    .demo-speed-select {
      padding: 7px 10px; border-radius: 8px;
      border: 1px solid var(--border); background: var(--bg-light);
      color: var(--text-secondary);
      font-family: 'JetBrains Mono', monospace; font-size: 0.82rem;
      cursor: pointer; outline: none;
    }
    .demo-chart-card {
      background: white; border: 1px solid var(--border); border-radius: 16px; overflow: hidden;
    }
    .demo-chart-header {
      display: flex; align-items: center; justify-content: space-between;
      padding: 14px 20px; border-bottom: 1px solid var(--border);
      background: var(--bg-light); flex-wrap: wrap; gap: 10px;
    }
    .demo-legend { display: flex; gap: 16px; flex-wrap: wrap; }
    .demo-legend-item { display: flex; align-items: center; gap: 6px; font-size: 0.82rem; color: var(--text-secondary); }
    .demo-legend-dot { width: 10px; height: 10px; border-radius: 50%; flex-shrink: 0; }
    .demo-legend-dash { width: 18px; height: 0; border-top: 2px dashed #9ca3af; flex-shrink: 0; }
    .demo-chart-body { padding: 16px 20px 8px; }
    .demo-chart-body canvas { width: 100% !important; display: block; }
    .demo-readouts {
      display: grid; grid-template-columns: repeat(3, 1fr);
      gap: 12px; padding: 12px 20px 20px;
    }
    .demo-readout {
      background: var(--bg-light); border: 1px solid var(--border);
      border-radius: 10px; padding: 12px 14px;
    }
    .demo-readout-label { font-size: 0.72rem; color: var(--text-secondary); letter-spacing: 0.06em; margin-bottom: 4px; font-weight: 500; }
    .demo-readout-val { font-family: 'JetBrains Mono', monospace; font-size: 1rem; font-weight: 600; line-height: 1; margin-bottom: 6px; }
    .demo-readout-bar-bg { height: 4px; background: var(--border); border-radius: 2px; overflow: hidden; }
    .demo-readout-bar-fill { height: 100%; border-radius: 2px; transition: width 0.1s ease; }

    /* Responsive */
    @media (max-width: 768px) {
      .hero h1 {
        font-size: 1.8rem;
      }

      .section-title {
        font-size: 1.5rem;
      }

      .stat-value {
        font-size: 2rem;
      }

      .figure-grid {
        grid-template-columns: 1fr;
      }

      .video-grid {
        grid-template-columns: repeat(auto-fill, minmax(240px, 1fr));
      }

      .comparison-grid {
        grid-template-columns: 1fr;
      }
    }
  </style>
</head>
<body>

<!-- Hero Section -->
<section class="hero">
  <div class="container">
    <div class="hero-content">
      <h1><span class="highlight">TOPReward</span>: <br>Token Probabilities as Hidden Zero-Shot Rewards for Robotics</h1>
      <p class="authors">
        <a href="#" style="color: inherit; text-decoration: none;">Shirui Chen</a><sup>1,2</sup>,
        <a href="#" style="color: inherit; text-decoration: none;">Cole Harrison</a><sup>3</sup>,
        <a href="#" style="color: inherit; text-decoration: none;">Ying-Chun Lee</a><sup>1</sup>,
        <a href="#" style="color: inherit; text-decoration: none;">Angela Jin Yang</a><sup>1</sup>,
        <a href="#" style="color: inherit; text-decoration: none;">Zhongzheng Ren</a><sup>1,2,4</sup>,<br>
        <a href="#" style="color: inherit; text-decoration: none;">Lillian J. Ratliff</a><sup>1</sup>,
        <a href="https://duanjiafei.com/" style="color: inherit; text-decoration: none;">Jiafei Duan</a><sup>1,2</sup><sup>*</sup>,
        <a href="https://homes.cs.washington.edu/~fox/" style="color: inherit; text-decoration: none;">Dieter Fox</a><sup>1,2</sup><sup>*</sup>,
        <a href="https://www.ranjaykrishna.com/index.html" style="color: inherit; text-decoration: none;">Ranjay Krishna</a><sup>1,2</sup><sup>*</sup>
      </p>
      <p style="font-size: 0.9rem; color: rgba(255,255,255,0.7); margin-bottom: 20px;">
        University of Washington<sup>1</sup> &nbsp;&nbsp;|&nbsp;&nbsp;
        Allen Institute for AI<sup>2</sup> &nbsp;&nbsp;|&nbsp;&nbsp;
        Amazon<sup>3</sup> &nbsp;&nbsp;|&nbsp;&nbsp;
        University of North Carolina<sup>4</sup>
      </p>
      <p style="font-size: 0.9rem; color: rgba(255,255,255,0.9); margin-bottom: 20px;">
        <sup>*</sup>Co-advised
      </p>
      <div class="btn-group">
        <a href="https://arxiv.org/pdf/2602.19313" class="btn btn-outline" target="_blank">
          <i class="ai ai-arxiv"></i> arXiv
        </a>
        <a href="https://github.com/TOPReward/TOPReward" class="btn btn-outline" target="_blank">
          <i class="fab fa-github"></i> Code
        </a>
      </div>
    </div>
  </div>
</section>

<!-- Teaser -->
<section class="teaser">
  <div class="container" style="text-align: center;">
    <img src="./static/images/Figure1.png" alt="TOPReward Overview" width="80%" style="height: auto;">
    <p class="teaser-caption">
      <b>TOPReward</b> enables effective zero-shot estimation of task progress across diverse and challenging real-world manipulation tasks. Moreover, we introduce our in-house robotics reward benchmark, <b>ManiRewardBench</b>.
    </p>
  </div>
</section>




<!-- Key Findings -->
<section>
  <div class="container">
    <h2 class="section-title">
      <span class="icon"><i class="fas fa-lightbulb"></i></span>
      Highlights
    </h2>

    <ul class="findings-list">
      <li>
        <span><strong>Zero-shot progress estimation:</strong> Use VLM token log-likelihoods as a dense temporal reward (no calibration).</span>
      </li>
      <li>
        <span><strong>Strong benchmark performance:</strong> Achieves mean VOC scores of 0.857 on Open X-Embodiment 
          and 0.947 on ManiRewardBench, outperforming GVL.</span>
      </li>
      <li>
        <span><strong>Useful downstream:</strong> Enables success detection and improves BC via advantage weighting.</span>
      </li>
      <li>
        <span><strong>Open-source model compatibility:</strong> Works with 
          Qwen3-VL-8B and other video VLMs, with improvements expected as video understanding 
          advances.</span>
      </li>
    </ul>
  </div>
</section>

<!-- Abstract -->
<section>
  <div class="container">
    <h2 class="section-title">
      <span class="icon"><i class="fas fa-align-left"></i></span>
      Abstract
    </h2>
    <div class="prose">
      <p>
        <!-- While Vision-Language-Action (VLA) models have seen rapid progress in pretraining, 
        their advancement in Reinforcement Learning (RL) remains hampered by 
        low sample efficiency and sparse rewards in real-world settings. Developing generalizable
         process reward models is essential for providing the fine-grained feedback necessary
          to bridge this gap. However, existing temporal value functions often fail to generalize
           beyond their training domains.  -->
           Vision-Language-Action (VLA) models have advanced in pretraining, but their RL performance 
           is limited by low sample efficiency and sparse real-world rewards. Generalizable process reward 
           models are needed, yet existing temporal value functions often fail to transfer across domains.
      </p>
      <p>
        We introduce <strong>TOPReward</strong>, a zero-shot progress estimator for robotic manipulation that reads
        <strong>task progress directly from video Vision-Language Models (VLMs) token probabilities</strong>. 
        Evaluated on Open X-Embodiment (39 datasets, 780 episodes) and our new <strong>ManiRewardBench</strong> (113 tasks, 497 episodes across Franka, YAM, and SO-100/101), 
        TOPReward achieves 0.945 mean VOC on ManiRewardBench using Qwen3-VL and outperforms GVL on open-source VLMs. 
        It also enables success detection and reward-aligned behavior cloning.
<!--         
        We evaluate TOPReward
        on both the Open X-Embodiment dataset (39 datasets, 780 episodes) and our newly introduced
        <strong>ManiRewardBench</strong> (113 tasks, 497 episodes across Franka, YAM, and SO-100/101 platforms). Across
        130+ distinct real-world tasks, TOPReward achieves 0.945 mean VOC on ManiRewardBench using Qwen3-VL and outperforms Generative Value Learning (GVL) 
        on open-source VLMs. TOPReward also supports <strong>success detection</strong> and <strong>reward-aligned behavior cloning</strong>. -->
      </p>
    </div>
<!-- 
    <div class="prose">
      <p>
        While Vision-Language-Action (VLA) models have seen rapid progress in pretraining, 
        their advancement in Reinforcement Learning (RL) remains hampered by 
        low sample efficiency and sparse rewards in real-world settings. Developing generalizable
         process reward models is essential for providing the fine-grained feedback necessary
          to bridge this gap. However, existing temporal value functions often fail to generalize
           beyond their training domains. 
      </p>
      <p>
        We introduce <strong>TOPReward</strong>, a novel, probabilistically grounded temporal value function that leverages
        the latent world knowledge of pretrained video Vision-Language Models (VLMs) to estimate robotic task progress.
        Unlike prior methods that prompt VLMs to directly output numeric progress values, which depend on VLM handling of
        literal number tokens, TOPReward extracts task progress directly from VLM token probabilities. We evaluate TOPReward
        on both the Open X-Embodiment dataset (39 datasets, 780 episodes) and our newly introduced
        <strong>ManiRewardBench</strong> (113 tasks, 497 episodes across Franka, YAM, and SO-100/101 platforms). Across
        130+ distinct real-world tasks, TOPReward achieves 0.945 mean VOC on ManiRewardBench using Qwen3-VL, dramatically
        outperforming the state-of-the-art baseline, Generative Value Learning (GVL), whose progress estimates exhibit
        negligible correlation with ground truth on the same open-source VLM. We further demonstrate that TOPReward serves
        as a versatile tool for downstream applications, including dataset filtering, success detection, and reward-aligned
        behavior cloning.
      </p>
    </div> -->

    <!-- Key Stats -->
    <div class="stats-grid">
      <div class="stat-card">
        <div class="stat-value">130+</div>
        <div class="stat-label">Zero-Shot Real-World Tasks</div>
      </div>
      
      <div class="stat-card">
        <div class="stat-value">0.945</div>
        <div class="stat-label">Mean VOC (Qwen3-VL)</div>
      </div>  
      <div class="stat-card">
        <div class="stat-value">3+</div>
        <div class="stat-label">Robot Platforms Evaluated</div>
      </div>
      <div class="stat-card">
        <div class="stat-value">0</div>
        <div class="stat-label">Task-Specific Training Required</div>
      </div>
    </div>
  </div>

</section>

<!-- Method -->
<section class="alt-bg">
  <div class="container">
    <h2 class="section-title">
      <span class="icon"><i class="fas fa-cogs"></i></span>
      Method Overview
    </h2>

    <figure class="method-figure" style="text-align: center;">
      <img src="./static/images/Figure2.png" alt="TOPReward Example">
      <figcaption>
        <strong>Qualitative example of "Fold the Towel":</strong> Instruction-conditioned progress estimation on a real trajectory.
        The curve shows TOPReward's predicted completion value over time, with annotated values at selected frames corresponding to 
        semantic sub-tasks.
      </figcaption>
    </figure>

    <div class="components-grid">
      <div class="component-card">
        <div class="component-num">1</div>
        <h4>Prompted Video–Language Inference</h4>
        <p>
          We ask the VLM model to judge whether the observed trajectory completes the instruction
           and score the log-likelihood of an affirmative answer (e.g. the token <i>True</i>). 
        </p>
      </div>

      <div class="component-card">
        <div class="component-num">2</div>
        <h4>Token-Probability Reward Extraction</h4>
        <!-- <p>
          Compute the log-likelihood of the answer token "True".
          This procedure entirely sidesteps the need for the language model to rely 
          on its instruction-following or numerical generation capabilities.
        </p> -->
        <p>
          Compute the log-likelihood of the answer token "True", avoiding reliance on the model’s instruction-following or numeric generation abilities.
        </p>
      </div>

      <div class="component-card">
        <div class="component-num">3</div>
        <h4>Progress Estimation from Trajectory Prefixes</h4>
        <p>
          The extracted token probabilities are aligned across time to produce a dense temporal reward function.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- Quantitative Results -->
<section>
  <div class="container">
    <h2 class="section-title">
      <span class="icon"><i class="fas fa-chart-line"></i></span>
      Quantitative Results
    </h2>

    <!-- Large-scale Evaluation -->
    <h3 style="font-size: 1.25rem; font-weight: 600; margin: 30px 0 16px;">
      Large-Scale Progress Estimation: Logit-Based Rewards Are More Reliable
    </h3>

    <!-- <p class="prose" style="margin-bottom: 20px;">
      We evaluate <strong>TOPReward</strong> as a zero-shot progress estimator on large-scale real-world robot datasets.
      Across both Open X-Embodiment (OXE) and ManiRewardBench, our likelihood-based formulation substantially
      outperforms the state-of-the-art GVL baseline on open-source VLMs, demonstrating that progress information
      is already encoded in pretrained video-language model logits.
    </p> -->

    <div class="results-table-container">
      <table class="results-table">
        <caption>
          <strong>Results on the Open X-Embodiment dataset.</strong>
      We report Mean VOC over 39 datasets with 20 episodes per dataset. Higher is better.
        </caption>
        <thead>
          <tr>
            <th class="method-name">Method</th>
            <th>Molmo-2-8B</th>
            <th>Qwen3-VL-8B</th>
            <th>Gemini-2.5-Pro</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td class="method-name">GVL</td>
            <td>-0.016</td>
            <td>0.194</td>
            <td><strong>0.541</strong></td>
          </tr>
          <tr class="highlight-row">
            <td class="method-name">TOPReward</td>
            <td><strong>0.417</strong></td>
            <td><strong>0.857</strong></td>
            <td>0.433</td>
          </tr>
        </tbody>
      </table>
    </div>

    <div class="results-table-container">
      <table class="results-table">
        <caption>
          <strong>Results on the ManiRewardBench.</strong>
          We report Mean VOC over 113 tasks, 497 episodes. Higher is better.
        </caption>

        <thead>
          <tr>
            <th class="method-name"></th>
            <th colspan="2">Molmo-2</th>
            <th colspan="2">Qwen3-VL-8B</th>
            <th colspan="2">Gemini<sup>*</sup></th>
          </tr>
          <tr>
            <th class="method-name">Dataset</th>
            <th>GVL</th>
            <th>TOPReward</th>
            <th>GVL</th>
            <th>TOPReward</th>
            <th>GVL</th>
            <th>TOPReward</th>
          </tr>
        </thead>

        <tbody>
          <tr>
            <td class="method-name">LeRobot</td>
            <td>-0.001</td>
            <td>0.595</td>
            <td>0.332</td>
            <td><strong>0.954</strong></td>
            <td>0.620</td>
            <td>0.578</td>
          </tr>
          <tr>
            <td class="method-name">Franka</td>
            <td>0.000</td>
            <td>0.662</td>
            <td>0.242</td>
            <td><strong>0.942</strong></td>
            <td>0.695</td>
            <td>0.448</td>
          </tr>
          <tr>
            <td class="method-name">Bimanual YAM</td>
            <td>0.007</td>
            <td>0.565</td>
            <td>0.164</td>
            <td><strong>0.947</strong></td>
            <td>0.566</td>
            <td>0.546</td>
          </tr>
          <tr>
            <td class="method-name">Single-arm YAM</td>
            <td>-0.017</td>
            <td>0.642</td>
            <td>0.544</td>
            <td><strong>0.945</strong></td>
            <td>0.752</td>
            <td>0.488</td>
          </tr>
        </tbody>
      </table>
    </div>

    <!-- Qualitative -->
    <figure class="full-figure" style="margin-top: 40px;">
      <img src="./static/images/linear_progress_examples1x4_3.png" alt="Progress Trace Comparison">
      <figcaption>
        <strong>Progress traces on ManiRewardBench.</strong>
         Example progress traces predicted by TOPReward (orange) compared to ground-truth completion (dashed) from ManiRewardBench. 
         We also overlay Gemini-GVL (blue) on the same episodes when available.
      </figcaption>
    </figure>

    <p class="prose" style="margin-top: 16px;">
    <!-- The traces demonstrate that TOPReward produces smooth, monotonically increasing progress signals that closely 
        track ground-truth task completion across diverse manipulation tasks. In contrast, Gemini-GVL (when available) 
        exhibits noisier predictions with frequent non-monotonic fluctuations. Notably, TOPReward correctly captures the 
        temporal structure of multi-step tasks, with progress plateaus corresponding to intermediate subtask completions 
        and accelerations during active manipulation phases. -->
        TOPReward generates smooth, steadily increasing progress signals that closely match ground-truth completion across tasks. 
        In contrast, Gemini-GVL produces noisier, non-monotonic predictions. TOPReward also captures multi-step structure, 
        with plateaus at subtask completion and sharper gains during active manipulation.
    </p>

    <!-- Success Detection -->
    <h3 style="font-size: 1.25rem; font-weight: 600; margin: 50px 0 16px;">
      Success Detection: Likelihood Beats Rank Correlation
    </h3>

    <p class="prose">
      VOC (Value-Order Correlation) measures rank consistency, not task completion, so failed trajectories that plateau early can still score high. 
      In contrast, TOPReward estimates instruction-satisfaction likelihood, better separating success from failure.
    </p>

    <p class="prose" style="margin-top: 16px;">
      We evaluate success detection on the ManiRewardBench failure split (23 tasks) as a binary classification problem, reporting ROC-AUC. TOPReward uses the 
      average log-likelihood of the last three sampled frames, while GVL uses VOC scores.
    </p>

    <!-- <p class="prose">
      VOC (Value-Order Correlation), a rank correlation metric, measures ordering, not completion. As a result, failed trajectories that plateau early can still
      achieve high VOC scores. TOPReward directly estimates the likelihood of instruction satisfaction,
      naturally distinguishing success from failure.
    </p> -->
<!-- 
    <p class="prose" style="margin-top: 16px;">
    We evaluate success detection on the failure trajectory split of ManiRewardBench, which contains both successful 
    and failed attempts across 23 tasks. We frame success detection as binary classification and report ROC-AUC. 
    For TOPReward, we use the average log-likelihood over the last 3 sampled frames; for GVL, we use the VOC score. 
    </p> -->

    <div class="results-table-container" style="margin-top: 20px;">
      <table class="results-table">
        <caption>
          <strong>Success detection results.</strong>
          <!-- We report ROC-AUC on ManiRewardBench. TOPReward matches or exceeds GVL across both open-source and proprietary models. -->
        </caption>
        <thead>
          <tr>
            <th class="method-name">Method</th>
            <th>Qwen3-VL-8B</th>
            <th>Gemini-2.5-Pro</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td class="method-name">GVL</td>
            <td>0.519</td>
            <td>0.823</td>
          </tr>
          <tr class="highlight-row">
            <td class="method-name">TOPReward (Ours)</td>
            <td><strong>0.654</strong></td>
            <td><strong>0.826</strong></td>
          </tr>
        </tbody>
      </table>
    </div>    
  </div>
</section>

<section class="alt-bg">
  <div class="container">
    <h2 class="section-title">
      <span class="icon"><i class="fas fa-sliders-h"></i></span>
      Live Demo
    </h2>

    <!-- Video + scrubber -->
    <div class="demo-card">
      <div class="demo-video-header">
        <span class="demo-task-label">Task: <strong>"Put the cube into the bowl."</strong> &nbsp;·&nbsp; Platform: <strong>SO-100/101</strong>&nbsp;</span>
        <span class="demo-t-badge" id="demoTBadge">t&nbsp;=&nbsp;0.000</span>
      </div>

      <div class="demo-video-wrap">
        <video id="demoVideo" preload="auto" muted playsinline>
          <source src="./static/videos/demo.mp4" type="video/mp4">
        </video>
        <div class="demo-vid-cursor" id="demoVidCursor"></div>
      </div>

      <div class="demo-scrubber-wrap">
        <div class="demo-scrubber-labels">
          <span>t = 0</span>
          <span>t = 1</span>
        </div>
        <input type="range" id="demoScrubber" class="demo-scrubber" min="0" max="1000" value="0">
      </div>

      <div class="demo-controls">
        <button class="demo-btn" id="demoStepBack">&#9664; Step</button>
        <button class="demo-btn demo-btn-play" id="demoPlayBtn">&#9654;&nbsp;Play</button>
        <button class="demo-btn" id="demoStepFwd">Step &#9654;</button>
        <select id="demoSpeed" class="demo-speed-select">
          <option value="0.25">0.25×</option>
          <option value="0.5">0.5×</option>
          <option value="1" selected>1×</option>
          <option value="2">2×</option>
        </select>
      </div>
    </div>

    <!-- Chart -->
    <div class="demo-chart-card">
      <div class="demo-chart-header">
        <span style="font-weight:600;font-size:0.95rem;">Predicted Progress over Time</span>
        <div class="demo-legend">
          <span class="demo-legend-item"><span class="demo-legend-dot" style="background:#f97316"></span>TOPReward (Qwen3-VL-8B)</span>
          <span class="demo-legend-item"><span class="demo-legend-dot" style="background:#2563eb"></span>GVL (Gemini-2.5-Pro)</span>
          <span class="demo-legend-item"><span class="demo-legend-dash"></span>Ground Truth</span>
        </div>
      </div>

      <div class="demo-chart-body">
        <canvas id="demoChart"></canvas>
      </div>

      <div class="demo-readouts">
        <div class="demo-readout">
          <div class="demo-readout-label">TOPReward</div>
          <div class="demo-readout-val" id="demoValTop" style="color:#f97316">0.000</div>
          <div class="demo-readout-bar-bg"><div class="demo-readout-bar-fill" id="demoBarTop" style="background:#f97316;width:0%"></div></div>
        </div>
        <div class="demo-readout">
          <div class="demo-readout-label">GVL (Gemini-2.5-Pro)</div>
          <div class="demo-readout-val" id="demoValGvl" style="color:#2563eb">0.000</div>
          <div class="demo-readout-bar-bg"><div class="demo-readout-bar-fill" id="demoBarGvl" style="background:#2563eb;width:0%"></div></div>
        </div>
        <div class="demo-readout">
          <div class="demo-readout-label">Ground Truth</div>
          <div class="demo-readout-val" id="demoValGt" style="color:#9ca3af">0.000</div>
          <div class="demo-readout-bar-bg"><div class="demo-readout-bar-fill" id="demoBarGt" style="background:#9ca3af;width:0%"></div></div>
        </div>
      </div>
    </div>

  </div>
</section>

<!-- Real-World Deployment Results -->
<section class="alt-bg">
  <div class="container">
    <h2 class="section-title">
      <span class="icon"><i class="fas fa-flask"></i></span>
      Real-World Deployment
    </h2>

    <p class="prose">
      We deploy <strong>TOPReward</strong> on a real single-arm SO-100 robot to compute advantage weights for imitation learning.
      Using only 50 noisy demonstrations per task, we apply advantage-weighted regression (AWR) combined with TOPReward (TOP-AWR).
      Across all 6 tasks, advantage-weighted regression (AWR) consistently improves the number of successes over standard behavior cloning (BC).
    </p>

    <div class="results-table-container" style="margin-top: 20px;">
      <table class="results-table">
        <caption>
          <strong>Real-World Experiments.</strong>
          We report number of successes (out of 10 trials) for advantage-weighted behavior cloning on single-arm SO-100 tasks.
        </caption>
        <thead>
          <tr>
            <th class="method-name">Task</th>
            <th>Pretrained</th>
            <th>BC</th>
            <th>TOP-AWR (Ours)</th>
          </tr>
        </thead>

        <tbody>
          <tr>
            <td class="method-name">Place toy car in box</td>
            <td>1</td>
            <td>2</td>
            <td><strong>3</strong></td>
          </tr>
          <tr>
            <td class="method-name">Stack red cube on green cube</td>
            <td>1.3</td>
            <td>1</td>
            <td><strong>2.3</strong></td>
          </tr>
          <tr>
            <td class="method-name">Put pen into cup</td>
            <td>1.7</td>
            <td>5.7</td>
            <td><strong>6.3</strong></td>
          </tr>
          <tr>
            <td class="method-name">Place doll in box</td>
            <td>0</td>
            <td>7</td>
            <td><strong>10</strong></td>
          </tr>
          <tr>
            <td class="method-name">Pick up cube</td>
            <td>4</td>
            <td>7</td>
            <td><strong>10</strong></td>
          </tr>
          <tr>
            <td class="method-name">Put cube in cup</td>
            <td>4</td>
            <td>6</td>
            <td><strong>9</strong></td>
          </tr>
        </tbody>
      </table>
    </div>
    
    <h3 style="font-size: 1.25rem; font-weight: 600; margin: 30px 0 16px;">
      LeRobot Rollouts
    </h3>

    <div class="video-grid">
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/car_box.mp4" type="video/mp4">
        </video>
        <div class="video-label">Pretrained - Place toy car in box <span class="cross">&#10007;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/car_box_depi.mp4" type="video/mp4">
        </video>
        <div class="video-label">Behavior Cloning (BC) - Place toy car in box <span class="cross">&#10007;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/car_box_depi_adv.mp4" type="video/mp4">
        </video>
        <div class="video-label">TOP-AWR (Ours) - Place toy car in box <span class="check">&#10003;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/put_cube_cup.mp4" type="video/mp4">
        </video>
        <div class="video-label">Pretrained - Put cube in cup <span class="cross">&#10007;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/put_cube_cup_depi.mp4" type="video/mp4">
        </video>
        <div class="video-label">Behavior Cloning (BC) - Put cube in cup <span class="cross">&#10007;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/put_cube_cup_depi_adv.mp4" type="video/mp4">
        </video>
        <div class="video-label">TOP-AWR (Ours) - Put cube in cup <span class="check">&#10003;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/doll_box.mp4" type="video/mp4">
        </video>
        <div class="video-label">Pretrained - Place doll in box <span class="cross">&#10007;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/doll_box_depi.mp4" type="video/mp4">
        </video>
        <div class="video-label">Behavior Cloning (BC) - Place doll in box <span class="cross">&#10007;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/doll_box_depi_adv.mp4" type="video/mp4">
        </video>
        <div class="video-label">TOP-AWR (Ours) - Place doll in box <span class="check">&#10003;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/pen_cup.mp4" type="video/mp4">
        </video>
        <div class="video-label">Pretrained - Put pen into cup <span class="cross">&#10007;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/pen_cup_depi.mp4" type="video/mp4">
        </video>
        <div class="video-label">Behavior Cloning (BC) - Put pen into cup <span class="cross">&#10007;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/pen_cup_depi_adv.mp4" type="video/mp4">
        </video>
        <div class="video-label">TOP-AWR (Ours) - Put pen into cup <span class="check">&#10003;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/pick_cube.mp4" type="video/mp4">
        </video>
        <div class="video-label">Pretrained - Pick up cube <span class="cross">&#10007;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/pick_cube_depi.mp4" type="video/mp4">
        </video>
        <div class="video-label">Behavior Cloning (BC) - Pick up cube <span class="cross">&#10007;</span></div>
      </div>
      <div class="video-card">
        <video autoplay muted loop playsinline>
          <source src="./static/videos/pick_cube_depi_adv.mp4" type="video/mp4">
        </video>
        <div class="video-label">TOP-AWR (Ours) - Pick up cube <span class="check">&#10003;</span></div>
      </div>
    </div>
  </div>
</section>


<!-- Conclusion -->
<section class="alt-bg">
  <div class="container">
    <h2 class="section-title">
      <span class="icon"><i class="fas fa-flag-checkered"></i></span>
      Conclusion
    </h2>

    <div class="prose">
      <p>
        We introduced <strong>TOPReward</strong>, a zero-shot progress estimator for 
        robotic manipulation that interprets pretrained video VLM token likelihoods as temporal 
        value functions. By querying the model's belief about task completion rather 
        than relying on numerical output, TOPReward avoids the known limitations of VLMs in 
        instruction following and numeric reasoning.
      </p>
      <p>
        Experiments show that TOPReward consistently outperforms prior approaches across 
        diverse benchmarks and robot platforms, while enabling success detection and enhancing 
        behavior cloning in real-world manipulation tasks.
      </p>
    </div>

    <h3 style="font-size: 1.1rem; font-weight: 600; margin: 30px 0 16px;">Limitations and Future Work</h3>
    <ul class="findings-list">
      <li>
        <span><strong>Visual perception limits:</strong> Tasks requiring fine-grained spatial 
          reasoning may yield noisy progress signals if the VLM cannot distinguish intermediate 
          states.</span>
      </li>
      <li>
        <span><strong>Normalization constraints:</strong> Per-episode min-max normalization limits absolute 
          progress comparison across trajectories without calibration.</span>
      </li>
      <li>
        <span><strong>Model-dependent performance:</strong> Performance relies on the underlying VLM's video understanding; 
          stronger models should directly improve TOPReward.</span>
      </li>
    </ul>
  </div>
</section>

<!-- BibTeX -->
<section>
  <div class="container">
    <h2 class="section-title">
      <span class="icon"><i class="fas fa-quote-left"></i></span>
      BibTeX
    </h2>

    <div class="bibtex-box">
      <pre><code>@misc{chen2026topreward,
  title        = {TOPReward: Token Probabilities as Hidden Zero-Shot Rewards for Robotics},
  author       = {Shirui Chen and Cole Harrison and Ying-Chun Lee and Angela Jin Yang and Zhongzheng Ren and Lillian J. Ratliff and Jiafei Duan and Dieter Fox and Ranjay Krishna},
  year         = {2026},
  howpublished = {\url{https://topreward.github.io/webpage/}},
  note         = {Project page}
}</code></pre>
    </div>
  </div>
</section>

<!-- Footer -->
<footer>
  <div class="container">
    <p>
      Template inspired by <a href="https://github.com/nerfies/nerfies.github.io" target="_blank">Nerfies</a>.
    </p>
  </div>
</footer>


<script>
(function () {
  const TOP = [
    [0,0],[0.071428571,0.284264355],[0.142857143,0.463799737],
    [0.214285714,0.613412555],[0.285714286,0.653309307],[0.357142857,0.827857595],
    [0.428571429,0.963600058],[0.5,0.984639361],[0.571428571,0.996639556],
    [0.642857143,0.997379828],[0.714285714,0.998198023],[0.785714286,0.999737009],
    [0.857142857,0.99952272],[0.928571429,0.999581162],[1,1]
  ];
  const GVL = [
    [0,0],[0.052631579,0.75],[0.105263158,0.5],[0.157894737,0.1],
    [0.210526316,0.4],[0.263157895,0.3],[0.315789474,0],[0.368421053,0.2],
    [0.421052632,0.9],[0.473684211,0.15],[0.526315789,1],[0.578947368,1],
    [0.631578947,1],[0.684210526,1],[0.736842105,1],[0.789473684,1],
    [0.842105263,1],[0.894736842,1],[0.947368421,1],[1,1]
  ];
  const GT = [
    [0,0],[0.071428571,0.2],[0.142857143,0.33],[0.214285714,0.52],
    [0.285714286,0.76],[0.357142857,0.9],[0.428571429,1],[0.5,1],
    [0.571428571,1],[0.642857143,1],[0.714285714,1],[0.785714286,1],
    [0.857142857,1],[0.928571429,1],[1,1]
  ];

  function lerp(data, t) {
    if (t <= data[0][0]) return data[0][1];
    if (t >= data[data.length - 1][0]) return data[data.length - 1][1];
    for (let i = 0; i < data.length - 1; i++) {
      if (t >= data[i][0] && t <= data[i + 1][0]) {
        const f = (t - data[i][0]) / (data[i + 1][0] - data[i][0]);
        return data[i][1] + f * (data[i + 1][1] - data[i][1]);
      }
    }
    return 0;
  }

  const canvas = document.getElementById('demoChart');
  const ctx    = canvas.getContext('2d');
  const PL = 48, PR = 16, PT = 14, PB = 36;
  let CW, CH = 210;

  function resizeCanvas() {
    CW = canvas.parentElement.clientWidth - 40;
    canvas.width = CW; canvas.height = CH;
    drawChart(curT);
  }

  function toPx(t, v) {
    return [PL + t * (CW - PL - PR), PT + (1 - v) * (CH - PT - PB)];
  }

  function drawGrid() {
    ctx.strokeStyle = '#e2e8f0'; ctx.lineWidth = 1; ctx.setLineDash([4, 4]);
    ctx.fillStyle = '#94a3b8'; ctx.textAlign = 'right';
    ctx.font = '10px JetBrains Mono, monospace';
    for (let v = 0; v <= 1; v += 0.25) {
      const [, y] = toPx(0, v);
      ctx.beginPath(); ctx.moveTo(PL, y); ctx.lineTo(CW - PR, y); ctx.stroke();
      ctx.fillText(v.toFixed(2), PL - 4, y + 4);
    }
    ctx.textAlign = 'center';
    for (let t = 0; t <= 1; t += 0.25) {
      const [x] = toPx(t, 0);
      ctx.beginPath(); ctx.moveTo(x, PT); ctx.lineTo(x, CH - PB); ctx.stroke();
      ctx.fillText(t.toFixed(2), x, CH - 6);
    }
    ctx.setLineDash([]); ctx.textAlign = 'left';
  }

  function drawLine(data, color, dashed, width) {
    ctx.beginPath();
    ctx.strokeStyle = color; ctx.lineWidth = width || 2;
    ctx.setLineDash(dashed ? [6, 4] : []);
    data.forEach(([t, v], i) => {
      const [x, y] = toPx(t, v);
      i === 0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y);
    });
    ctx.stroke(); ctx.setLineDash([]);
  }

  function drawChart(t) {
    if (!CW) return;
    ctx.clearRect(0, 0, CW, CH);
    drawGrid();
    drawLine(GT,  '#9ca3af', true,  1.8);
    drawLine(GVL, '#2563eb', false, 2);
    drawLine(TOP, '#f97316', false, 2.5);

    /* vertical cursor */
    const [cx] = toPx(t, 0);
    ctx.beginPath(); ctx.strokeStyle = 'rgba(30,41,59,0.3)'; ctx.lineWidth = 1.5;
    ctx.setLineDash([4, 3]); ctx.moveTo(cx, PT); ctx.lineTo(cx, CH - PB); ctx.stroke();
    ctx.setLineDash([]);

    /* dots */
    [[TOP, '#f97316'], [GVL, '#2563eb'], [GT, '#9ca3af']].forEach(([d, c]) => {
      const v = lerp(d, t);
      const [dx, dy] = toPx(t, v);
      ctx.beginPath(); ctx.arc(dx, dy, 5, 0, Math.PI * 2);
      ctx.fillStyle = c; ctx.fill();
      ctx.strokeStyle = '#fff'; ctx.lineWidth = 1.5; ctx.stroke();
    });
  }

  let curT = 0, playing = false, rafId, lastTs;
  const video      = document.getElementById('demoVideo');
  const scrubber   = document.getElementById('demoScrubber');
  const tBadge     = document.getElementById('demoTBadge');
  const vidCursor  = document.getElementById('demoVidCursor');
  const playBtn    = document.getElementById('demoPlayBtn');

  function setT(t) {
    curT = Math.max(0, Math.min(1, t));
    scrubber.value = curT * 1000;
    tBadge.textContent = 't\u00a0=\u00a0' + curT.toFixed(3);
    vidCursor.style.left = (curT * 100) + '%';

    if (video.duration && isFinite(video.duration))
      video.currentTime = curT * video.duration;

    const tv = lerp(TOP, curT), gv = lerp(GVL, curT), gtv = lerp(GT, curT);
    document.getElementById('demoValTop').textContent = tv.toFixed(3);
    document.getElementById('demoValGvl').textContent = gv.toFixed(3);
    document.getElementById('demoValGt').textContent  = gtv.toFixed(3);
    document.getElementById('demoBarTop').style.width = (tv  * 100) + '%';
    document.getElementById('demoBarGvl').style.width = (gv  * 100) + '%';
    document.getElementById('demoBarGt').style.width  = (gtv * 100) + '%';
    drawChart(curT);
  }

  scrubber.addEventListener('input', () => { stopPlay(); setT(scrubber.value / 1000); });

  function stopPlay() {
    playing = false;
    playBtn.innerHTML = '&#9654;&nbsp;Play';
    cancelAnimationFrame(rafId);
  }

  function startPlay() {
    playing = true;
    playBtn.innerHTML = '&#9646;&#9646;&nbsp;Pause';
    lastTs = null;
    rafId = requestAnimationFrame(animStep);
  }

  function animStep(ts) {
    if (!lastTs) lastTs = ts;
    const speed = parseFloat(document.getElementById('demoSpeed').value);
    const dt = (ts - lastTs) / 1000 * speed;
    lastTs = ts;
    const next = curT + dt * 0.2;   /* full range in ~5 s at 1× */
    if (next >= 1) { setT(1); stopPlay(); return; }
    setT(next);
    rafId = requestAnimationFrame(animStep);
  }

  playBtn.addEventListener('click', () => {
    if (playing) stopPlay();
    else { if (curT >= 1) setT(0); startPlay(); }
  });
  document.getElementById('demoStepBack').addEventListener('click', () => { stopPlay(); setT(curT - 1/14); });
  document.getElementById('demoStepFwd').addEventListener('click',  () => { stopPlay(); setT(curT + 1/14); });

  window.addEventListener('resize', resizeCanvas);
  video.addEventListener('loadedmetadata', () => setT(0));
  setT(0);
  setTimeout(resizeCanvas, 60);
})();
</script>

</body>
</html>
